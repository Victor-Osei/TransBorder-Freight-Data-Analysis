{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading packages...Successful.\n"
     ]
    }
   ],
   "source": [
    "# Loading the packages I will need:\n",
    "\n",
    "print(\"Loading packages...\", end = '')\n",
    "\n",
    "import numpy as np\n",
    "from pyunpack import Archive \n",
    "import pandas as pd \n",
    "import missingno as msno\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import zipfile\n",
    "import shutil  # For handling directories\n",
    "\n",
    "\n",
    "print(\"Successful.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 161 CSV files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\1526207693.py:17: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Path to the data folder\n",
    "data_folder = \"data\"\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Traverse through the year and month folders to find CSV files\n",
    "for year_folder in os.listdir(data_folder):\n",
    "    year_path = os.path.join(data_folder, year_folder)\n",
    "    if os.path.isdir(year_path):\n",
    "        for month_folder in os.listdir(year_path):\n",
    "            month_path = os.path.join(year_path, month_folder)\n",
    "            if os.path.isdir(month_path):\n",
    "                for file in os.listdir(month_path):\n",
    "                    if file.endswith('.csv'):\n",
    "                        file_path = os.path.join(month_path, file)\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        dataframes.append(df)\n",
    "\n",
    "# Check if any CSV files were loaded\n",
    "if not dataframes:\n",
    "    print(\"No CSV files found in the data folder.\")\n",
    "else:\n",
    "    # Display the list of CSV files loaded\n",
    "    print(f\"Loaded {len(dataframes)} CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6517225 entries, 0 to 6517224\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   TRDTYPE          int64  \n",
      " 1   USASTATE         object \n",
      " 2   DEPE             object \n",
      " 3   DISAGMOT         int64  \n",
      " 4   MEXSTATE         object \n",
      " 5   CANPROV          object \n",
      " 6   COUNTRY          int64  \n",
      " 7   VALUE            int64  \n",
      " 8   SHIPWT           int64  \n",
      " 9   FREIGHT_CHARGES  int64  \n",
      " 10  DF               float64\n",
      " 11  CONTCODE         object \n",
      " 12  MONTH            int64  \n",
      " 13  YEAR             int64  \n",
      " 14  COMMODITY2       float64\n",
      "dtypes: float64(2), int64(8), object(5)\n",
      "memory usage: 745.8+ MB\n",
      "   TRDTYPE USASTATE  DEPE  DISAGMOT MEXSTATE CANPROV  COUNTRY    VALUE  \\\n",
      "0        1       AK  0115         5      NaN      XB     1220     4660   \n",
      "1        1       AK  0901         5      NaN      XO     1220    14360   \n",
      "2        1       AK  20XX         1       XX     NaN     2010  4293733   \n",
      "3        1       AK  20XX         3      NaN      XA     1220    28283   \n",
      "4        1       AK  20XX         3      NaN      XA     1220    29848   \n",
      "\n",
      "     SHIPWT  FREIGHT_CHARGES   DF CONTCODE  MONTH  YEAR  COMMODITY2  \n",
      "0         0               67  2.0        X      4  2020         NaN  \n",
      "1         0              282  1.0        X      4  2020         NaN  \n",
      "2  24971000                0  1.0        0      4  2020         NaN  \n",
      "3       443              563  1.0        X      4  2020         NaN  \n",
      "4        69              538  2.0        X      4  2020         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Check if any DataFrames were loaded\n",
    "if not dataframes:\n",
    "    print(\"No DataFrames to concatenate.\")\n",
    "else:\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Display the combined DataFrame information\n",
    "    combined_df.info()\n",
    "\n",
    "    # Display the first few rows of the combined DataFrame to inspect\n",
    "    print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRDTYPE</th>\n",
       "      <th>USASTATE</th>\n",
       "      <th>DEPE</th>\n",
       "      <th>DISAGMOT</th>\n",
       "      <th>MEXSTATE</th>\n",
       "      <th>CANPROV</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>SHIPWT</th>\n",
       "      <th>FREIGHT_CHARGES</th>\n",
       "      <th>DF</th>\n",
       "      <th>CONTCODE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COMMODITY2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>0115</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XB</td>\n",
       "      <td>1220</td>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>0901</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XO</td>\n",
       "      <td>1220</td>\n",
       "      <td>14360</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>1</td>\n",
       "      <td>XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>4293733</td>\n",
       "      <td>24971000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>28283</td>\n",
       "      <td>443</td>\n",
       "      <td>563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XA</td>\n",
       "      <td>1220</td>\n",
       "      <td>29848</td>\n",
       "      <td>69</td>\n",
       "      <td>538</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XC</td>\n",
       "      <td>1220</td>\n",
       "      <td>6699</td>\n",
       "      <td>248</td>\n",
       "      <td>142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>20XX</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XC</td>\n",
       "      <td>1220</td>\n",
       "      <td>9103</td>\n",
       "      <td>15</td>\n",
       "      <td>208</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRDTYPE USASTATE  DEPE  DISAGMOT MEXSTATE CANPROV  COUNTRY    VALUE  \\\n",
       "0        1       AK  0115         5      NaN      XB     1220     4660   \n",
       "1        1       AK  0901         5      NaN      XO     1220    14360   \n",
       "2        1       AK  20XX         1       XX     NaN     2010  4293733   \n",
       "3        1       AK  20XX         3      NaN      XA     1220    28283   \n",
       "4        1       AK  20XX         3      NaN      XA     1220    29848   \n",
       "5        1       AK  20XX         3      NaN      XC     1220     6699   \n",
       "6        1       AK  20XX         3      NaN      XC     1220     9103   \n",
       "\n",
       "     SHIPWT  FREIGHT_CHARGES   DF CONTCODE  MONTH  YEAR  COMMODITY2  \n",
       "0         0               67  2.0        X      4  2020         NaN  \n",
       "1         0              282  1.0        X      4  2020         NaN  \n",
       "2  24971000                0  1.0        0      4  2020         NaN  \n",
       "3       443              563  1.0        X      4  2020         NaN  \n",
       "4        69              538  2.0        X      4  2020         NaN  \n",
       "5       248              142  1.0        X      4  2020         NaN  \n",
       "6        15              208  2.0        X      4  2020         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "TRDTYPE                  0\n",
      "USASTATE            915116\n",
      "DEPE               4101624\n",
      "DISAGMOT                 0\n",
      "MEXSTATE           4677264\n",
      "CANPROV            3119497\n",
      "COUNTRY                  0\n",
      "VALUE                    0\n",
      "SHIPWT                   0\n",
      "FREIGHT_CHARGES          0\n",
      "DF                 2184568\n",
      "CONTCODE                 0\n",
      "MONTH                    0\n",
      "YEAR                     0\n",
      "COMMODITY2         1500485\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(combined_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to check unique values in each column just to be on the safe side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column TRDTYPE:\n",
      "[1 2]\n",
      "\n",
      "\n",
      "Unique values in column USASTATE:\n",
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'DU' 'FL' 'GA' 'HI' 'IA'\n",
      " 'ID' 'IL' 'IN' 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT'\n",
      " 'NC' 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC'\n",
      " 'SD' 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI' 'WV' 'WY' nan]\n",
      "\n",
      "\n",
      "Unique values in column DEPE:\n",
      "['0115' '0901' '20XX' '2303' '2304' '2305' '2408' '2506' '3001' '3004'\n",
      " '3009' '3023' '30XX' '3101' '3103' '3104' '3106' '3126' '31XX' '3310'\n",
      " '3613' '3801' '3802' '4101' '4102' '41XX' '70XX' '0106' '01XX' '0701'\n",
      " '0708' '0712' '07XX' '09XX' '10XX' '17XX' '18XX' '19XX' '2006' '2301'\n",
      " '2310' '2401' '2402' '2403' '2404' '2503' '2507' '2601' '2604' '2608'\n",
      " '27XX' '3019' '3302' '33XX' '3401' '3403' '3422' '34XX' '3501' '35XX'\n",
      " '3604' '3803' '38XX' '5201' '5203' '52XX' '0209' '02XX' '0704' '3301'\n",
      " '3424' '5301' '55XX' '0715' '11XX' '24XX' '2501' '2603' '2605' '2606'\n",
      " '26XX' '2720' '2801' '29XX' '3011' '3020' '3318' '4115' '53XX' '0101'\n",
      " '0102' '0110' '0212' '13XX' '2302' '2307' '2504' '2505' '25XX' '2602'\n",
      " '2704' '28XX' '3002' '3003' '3005' '3007' '3008' '3013' '3025' '32XX'\n",
      " '3304' '3308' '3316' '3322' '3405' '3408' '3805' '3809' '3819' '3901'\n",
      " '39XX' '4105' '4110' '49XX' '5501' '3307' '45XX' '0104' '0211' '04XX'\n",
      " '1012' '1704' '80XX' '51XX' '0118' '0127' '14XX' '16XX' '3410' '36XX'\n",
      " '3808' '0108' '3306' '0105' '1003' '3012' '3321' '3323' '3404' '3014'\n",
      " '3423' '37XX' '3804' '0201' '0417' '2007' '3102' '0103' '0107' '0109'\n",
      " '0203' '0206' '3016' '3022' '3409' '3425' '3426' '3430' '3305' '3406'\n",
      " '3421' '3814' '1902' '3010' '3309' '3317' '0714' '15XX' '21XX' '54XX'\n",
      " '3407' '3413' '3414' '3415' '3416' '3417' '3419' '3420' '0207' '0904'\n",
      " '2406' '4104' '0112' '2383' '3701' '4103' '0121' '05XX' '2309' '23XX'\n",
      " '3303' '59XX' '3017' '3815' '3026' '3029' '3111' '1603' '3411' '3807'\n",
      " '3015' '4504' '1303' '3806' '0906' '3816' '0131' '0903' '1502' '3006' nan\n",
      " '2609' '3325' '0706' '3105' '3115' '60XX' '3427' '3324' '3384' '3842'\n",
      " '3018' '3818' '3882' '0905' '3433' '0182' '2481' '3082' '2407' '2502'\n",
      " '3843' '3434' '0111' '3881' '3385' '0152']\n",
      "\n",
      "\n",
      "Unique values in column DISAGMOT:\n",
      "[5 1 3 6 8 7 4 9]\n",
      "\n",
      "\n",
      "Unique values in column MEXSTATE:\n",
      "[nan 'XX' 'CO' 'NL' 'CH' 'CM' 'GT' 'JA' 'MX' 'OT' 'QT' 'SL' 'BC' 'BS' 'DF'\n",
      " 'TM' 'ZA' 'DG' 'HG' 'SO' 'AG' 'MI' 'MO' 'PU' 'TL' 'VE' 'SI' 'YU' 'TB'\n",
      " 'CS' 'CL' 'OA' 'QR' 'GR']\n",
      "\n",
      "\n",
      "Unique values in column CANPROV:\n",
      "['XB' 'XO' nan 'XA' 'XC' 'XM' 'XQ' 'XY' 'XW' 'XS' 'XN' 'XP' 'OT' 'XT' 'XV']\n",
      "\n",
      "\n",
      "Unique values in column COUNTRY:\n",
      "[1220 2010]\n",
      "\n",
      "\n",
      "Unique values in column VALUE:\n",
      "[   4660   14360 4293733 ... 5148154 1168062 4384342]\n",
      "\n",
      "\n",
      "Unique values in column SHIPWT:\n",
      "[       0 24971000      443 ...   663103  1823041  9137618]\n",
      "\n",
      "\n",
      "Unique values in column FREIGHT_CHARGES:\n",
      "[     67     282       0 ... 1634298  127050  391893]\n",
      "\n",
      "\n",
      "Unique values in column DF:\n",
      "[ 2.  1. nan]\n",
      "\n",
      "\n",
      "Unique values in column CONTCODE:\n",
      "['X' '0' '1' 0 1]\n",
      "\n",
      "\n",
      "Unique values in column MONTH:\n",
      "[ 4  8  2  1  7  6  3  5  9 12 11 10]\n",
      "\n",
      "\n",
      "Unique values in column YEAR:\n",
      "[2020 2021 2022 2023 2024]\n",
      "\n",
      "\n",
      "Unique values in column COMMODITY2:\n",
      "[nan  2.  3.  4. 10. 13. 19. 23. 26. 27. 29. 39. 44. 48. 62. 63. 72. 73.\n",
      " 74. 76. 83. 84. 85. 86. 87. 88. 90. 94. 95. 98.  1.  5. 11. 12. 15. 16.\n",
      " 17. 18. 20. 21. 25. 28. 30. 31. 32. 33. 34. 35. 38. 40. 47. 49. 54. 55.\n",
      " 56. 57. 58. 59. 60. 61. 64. 65. 67. 68. 69. 70. 75. 78. 81. 82. 89. 93.\n",
      " 96.  7.  8. 22. 36. 42. 51. 71. 79.  6.  9. 24. 41. 52. 53. 80. 91. 92.\n",
      " 97. 14. 37. 43. 45. 46. 66. 50. 99.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for each column\n",
    "for column in combined_df.columns:\n",
    "    unique_values = combined_df[column].unique()\n",
    "    print(f\"Unique values in column {column}:\")\n",
    "    print(unique_values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now crosscheck from the data dictionary and make comparisons on the unique vales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMODITY2 change from float to int \n",
    "\n",
    "(CONTCODE) Code Containerized? \n",
    "X Containerized \n",
    "0 Non-Containerized \n",
    "\n",
    "\n",
    "DF from float to int\n",
    "\n",
    "Country Code (COUNTRY) int to obj\n",
    "Code Country \n",
    "1220 Canada \n",
    "2010 Mexico\n",
    "\n",
    "Domestic/Foreign Code (DF) float to object \n",
    "Distinguishes whether the merchandise was produced in the U.S. \n",
    "Code \n",
    "1 domestically produced merchandise \n",
    "2 foreign produced merchandise\n",
    "\n",
    "Mode of Transportation Code (DISAGMOT) int to object \n",
    "Code Description \n",
    "1 Vessel \n",
    "3 Air \n",
    "4 Mail (U.S. Postal Service) \n",
    "5 Truck \n",
    "6 Rail \n",
    "7 Pipeline \n",
    "8 Other \n",
    "9 Foreign Trade Zones (FTZs)\n",
    "\n",
    "Month (MONTH) int to datetime \n",
    "Month Code \n",
    "Month \n",
    "1 January \n",
    "2 February \n",
    "3 March \n",
    "4 April \n",
    "5 May \n",
    "6 June \n",
    "7 July \n",
    "8 August \n",
    "9 September \n",
    "10 October \n",
    "11 November \n",
    "12 December\n",
    "\n",
    "DEPE no need\n",
    "\n",
    "Shipping Weight (SHIPWT) no need Weight in Kilograms\n",
    "\n",
    "Trade Type Code (TRDTYPE) int to obj \n",
    "Code Trade Type \n",
    "1 Export \n",
    "2 Import\n",
    "\n",
    "USASTATE no need\n",
    "\n",
    "Value (VALUE) Value of Goods in United States Dollars\n",
    "\n",
    "Year (YEAR) int to datetime\n",
    "\n",
    "Freight Charges (FREIGHT_CHARGES) no need Freight Charges in U.S. Dollars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill non-finite values in COMMODITY2 with 0 and change from float to int\n",
    "combined_df['COMMODITY2'] = combined_df['COMMODITY2'].fillna(0).astype(int)\n",
    "\n",
    "# Change CONTCODE from code to descriptive text\n",
    "combined_df['CONTCODE'] = combined_df['CONTCODE'].replace({\n",
    "    'X': 'Containerized',\n",
    "    '0': 'Non-Containerized'\n",
    "}) \n",
    "\n",
    "# Change COUNTRY from int to object and replace values\n",
    "combined_df['COUNTRY'] = combined_df['COUNTRY'].astype(str).replace({\n",
    "    '1220': 'Canada',\n",
    "    '2010': 'Mexico'\n",
    "})\n",
    "\n",
    "# Change DF from float to object and replace values\n",
    "combined_df['DF'] = combined_df['DF'].astype(str).replace({\n",
    "    '1.0': 'domestic pr. merch',\n",
    "    '2.0': 'foreign pr. merch'\n",
    "})\n",
    "\n",
    "# Change DISAGMOT from int to object and replace values\n",
    "combined_df['DISAGMOT'] = combined_df['DISAGMOT'].astype(str).replace({\n",
    "    '1': 'Vessel',\n",
    "    '3': 'Air',\n",
    "    '4': 'Mail (U.S. Postal Service)',\n",
    "    '5': 'Truck',\n",
    "    '6': 'Rail',\n",
    "    '7': 'Pipeline',\n",
    "    '8': 'Other',\n",
    "    '9': 'Foreign Trade Zones (FTZs)'\n",
    "})\n",
    "\n",
    "# Change MONTH from int to descriptive text\n",
    "combined_df['MONTH'] = combined_df['MONTH'].astype(str).replace({\n",
    "    '1': 'January',\n",
    "    '2': 'February',\n",
    "    '3': 'March',\n",
    "    '4': 'April',\n",
    "    '5': 'May',\n",
    "    '6': 'June',\n",
    "    '7': 'July',\n",
    "    '8': 'August',\n",
    "    '9': 'September',\n",
    "    '10': 'October',\n",
    "    '11': 'November',\n",
    "    '12': 'December'\n",
    "})\n",
    "\n",
    "# Change TRDTYPE from int to object and replace values\n",
    "combined_df['TRDTYPE'] = combined_df['TRDTYPE'].astype(str).replace({\n",
    "    '1': 'Export',\n",
    "    '2': 'Import'\n",
    "})\n",
    "\n",
    "# Ensure YEAR column is in datetime format and extract the year as string\n",
    "combined_df['YEAR'] = pd.to_datetime(combined_df['YEAR'], errors='coerce', format='%Y')\n",
    "combined_df['YEAR'] = combined_df['YEAR'].dt.year.astype(str)\n",
    "\n",
    "# Assign the updated DataFrame to a new variable df\n",
    "df = combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the TRDTYPE column:\n",
      "['Export' 'Import']\n",
      "\n",
      "\n",
      "Unique values in the USASTATE column:\n",
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'DU' 'FL' 'GA' 'HI' 'IA'\n",
      " 'ID' 'IL' 'IN' 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT'\n",
      " 'NC' 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC'\n",
      " 'SD' 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI' 'WV' 'WY' nan]\n",
      "\n",
      "\n",
      "Unique values in the DEPE column:\n",
      "['0115' '0901' '20XX' '2303' '2304' '2305' '2408' '2506' '3001' '3004'\n",
      " '3009' '3023' '30XX' '3101' '3103' '3104' '3106' '3126' '31XX' '3310'\n",
      " '3613' '3801' '3802' '4101' '4102' '41XX' '70XX' '0106' '01XX' '0701'\n",
      " '0708' '0712' '07XX' '09XX' '10XX' '17XX' '18XX' '19XX' '2006' '2301'\n",
      " '2310' '2401' '2402' '2403' '2404' '2503' '2507' '2601' '2604' '2608'\n",
      " '27XX' '3019' '3302' '33XX' '3401' '3403' '3422' '34XX' '3501' '35XX'\n",
      " '3604' '3803' '38XX' '5201' '5203' '52XX' '0209' '02XX' '0704' '3301'\n",
      " '3424' '5301' '55XX' '0715' '11XX' '24XX' '2501' '2603' '2605' '2606'\n",
      " '26XX' '2720' '2801' '29XX' '3011' '3020' '3318' '4115' '53XX' '0101'\n",
      " '0102' '0110' '0212' '13XX' '2302' '2307' '2504' '2505' '25XX' '2602'\n",
      " '2704' '28XX' '3002' '3003' '3005' '3007' '3008' '3013' '3025' '32XX'\n",
      " '3304' '3308' '3316' '3322' '3405' '3408' '3805' '3809' '3819' '3901'\n",
      " '39XX' '4105' '4110' '49XX' '5501' '3307' '45XX' '0104' '0211' '04XX'\n",
      " '1012' '1704' '80XX' '51XX' '0118' '0127' '14XX' '16XX' '3410' '36XX'\n",
      " '3808' '0108' '3306' '0105' '1003' '3012' '3321' '3323' '3404' '3014'\n",
      " '3423' '37XX' '3804' '0201' '0417' '2007' '3102' '0103' '0107' '0109'\n",
      " '0203' '0206' '3016' '3022' '3409' '3425' '3426' '3430' '3305' '3406'\n",
      " '3421' '3814' '1902' '3010' '3309' '3317' '0714' '15XX' '21XX' '54XX'\n",
      " '3407' '3413' '3414' '3415' '3416' '3417' '3419' '3420' '0207' '0904'\n",
      " '2406' '4104' '0112' '2383' '3701' '4103' '0121' '05XX' '2309' '23XX'\n",
      " '3303' '59XX' '3017' '3815' '3026' '3029' '3111' '1603' '3411' '3807'\n",
      " '3015' '4504' '1303' '3806' '0906' '3816' '0131' '0903' '1502' '3006' nan\n",
      " '2609' '3325' '0706' '3105' '3115' '60XX' '3427' '3324' '3384' '3842'\n",
      " '3018' '3818' '3882' '0905' '3433' '0182' '2481' '3082' '2407' '2502'\n",
      " '3843' '3434' '0111' '3881' '3385' '0152']\n",
      "\n",
      "\n",
      "Unique values in the DISAGMOT column:\n",
      "['Truck' 'Vessel' 'Air' 'Rail' 'Other' 'Pipeline'\n",
      " 'Mail (U.S. Postal Service)' 'Foreign Trade Zones (FTZs)']\n",
      "\n",
      "\n",
      "Unique values in the MEXSTATE column:\n",
      "[nan 'XX' 'CO' 'NL' 'CH' 'CM' 'GT' 'JA' 'MX' 'OT' 'QT' 'SL' 'BC' 'BS' 'DF'\n",
      " 'TM' 'ZA' 'DG' 'HG' 'SO' 'AG' 'MI' 'MO' 'PU' 'TL' 'VE' 'SI' 'YU' 'TB'\n",
      " 'CS' 'CL' 'OA' 'QR' 'GR']\n",
      "\n",
      "\n",
      "Unique values in the CANPROV column:\n",
      "['XB' 'XO' nan 'XA' 'XC' 'XM' 'XQ' 'XY' 'XW' 'XS' 'XN' 'XP' 'OT' 'XT' 'XV']\n",
      "\n",
      "\n",
      "Unique values in the COUNTRY column:\n",
      "['Canada' 'Mexico']\n",
      "\n",
      "\n",
      "Unique values in the VALUE column:\n",
      "[   4660   14360 4293733 ... 5148154 1168062 4384342]\n",
      "\n",
      "\n",
      "Unique values in the SHIPWT column:\n",
      "[       0 24971000      443 ...   663103  1823041  9137618]\n",
      "\n",
      "\n",
      "Unique values in the FREIGHT_CHARGES column:\n",
      "[     67     282       0 ... 1634298  127050  391893]\n",
      "\n",
      "\n",
      "Unique values in the DF column:\n",
      "['foreign pr. merch' 'domestic pr. merch' 'nan']\n",
      "\n",
      "\n",
      "Unique values in the CONTCODE column:\n",
      "['Containerized' 'Non-Containerized' '1' 0 1]\n",
      "\n",
      "\n",
      "Unique values in the MONTH column:\n",
      "['April' 'August' 'February' 'January' 'July' 'June' 'March' 'May'\n",
      " 'September' 'December' 'November' 'October']\n",
      "\n",
      "\n",
      "Unique values in the YEAR column:\n",
      "['2020' '2021' '2022' '2023' '2024']\n",
      "\n",
      "\n",
      "Unique values in the COMMODITY2 column:\n",
      "[ 0  2  3  4 10 13 19 23 26 27 29 39 44 48 62 63 72 73 74 76 83 84 85 86\n",
      " 87 88 90 94 95 98  1  5 11 12 15 16 17 18 20 21 25 28 30 31 32 33 34 35\n",
      " 38 40 47 49 54 55 56 57 58 59 60 61 64 65 67 68 69 70 75 78 81 82 89 93\n",
      " 96  7  8 22 36 42 51 71 79  6  9 24 41 52 53 80 91 92 97 14 37 43 45 46\n",
      " 66 50 99]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for each column in the DataFrame\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in the {column} column:\")\n",
    "    print(unique_values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6517225 entries, 0 to 6517224\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   TRDTYPE          object\n",
      " 1   USASTATE         object\n",
      " 2   DEPE             object\n",
      " 3   DISAGMOT         object\n",
      " 4   MEXSTATE         object\n",
      " 5   CANPROV          object\n",
      " 6   COUNTRY          object\n",
      " 7   VALUE            int64 \n",
      " 8   SHIPWT           int64 \n",
      " 9   FREIGHT_CHARGES  int64 \n",
      " 10  DF               object\n",
      " 11  CONTCODE         object\n",
      " 12  MONTH            object\n",
      " 13  YEAR             object\n",
      " 14  COMMODITY2       int64 \n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 745.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display the updated DataFrame information\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE</th>\n",
       "      <th>SHIPWT</th>\n",
       "      <th>FREIGHT_CHARGES</th>\n",
       "      <th>COMMODITY2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.517225e+06</td>\n",
       "      <td>6.517225e+06</td>\n",
       "      <td>6.517225e+06</td>\n",
       "      <td>6.517225e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.945795e+06</td>\n",
       "      <td>1.200403e+06</td>\n",
       "      <td>3.851583e+04</td>\n",
       "      <td>4.375757e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.786455e+07</td>\n",
       "      <td>4.073193e+07</td>\n",
       "      <td>1.024961e+06</td>\n",
       "      <td>3.417434e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.434300e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.220900e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.630000e+02</td>\n",
       "      <td>4.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.345660e+05</td>\n",
       "      <td>2.391000e+03</td>\n",
       "      <td>2.900000e+03</td>\n",
       "      <td>7.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.595625e+09</td>\n",
       "      <td>9.068700e+09</td>\n",
       "      <td>2.487214e+08</td>\n",
       "      <td>9.900000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              VALUE        SHIPWT  FREIGHT_CHARGES    COMMODITY2\n",
       "count  6.517225e+06  6.517225e+06     6.517225e+06  6.517225e+06\n",
       "mean   2.945795e+06  1.200403e+06     3.851583e+04  4.375757e+01\n",
       "std    3.786455e+07  4.073193e+07     1.024961e+06  3.417434e+01\n",
       "min    0.000000e+00  0.000000e+00     0.000000e+00  0.000000e+00\n",
       "25%    1.434300e+04  0.000000e+00     0.000000e+00  6.000000e+00\n",
       "50%    7.220900e+04  0.000000e+00     2.630000e+02  4.000000e+01\n",
       "75%    4.345660e+05  2.391000e+03     2.900000e+03  7.900000e+01\n",
       "max    5.595625e+09  9.068700e+09     2.487214e+08  9.900000e+01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "TRDTYPE                  0\n",
      "USASTATE            915116\n",
      "DEPE               4101624\n",
      "DISAGMOT                 0\n",
      "MEXSTATE           4677264\n",
      "CANPROV            3119497\n",
      "COUNTRY                  0\n",
      "VALUE                    0\n",
      "SHIPWT                   0\n",
      "FREIGHT_CHARGES          0\n",
      "DF                       0\n",
      "CONTCODE                 0\n",
      "MONTH                    0\n",
      "YEAR                     0\n",
      "COMMODITY2               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in the DataFrame\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.shape[0]}\")\n",
    "\n",
    "# Display the duplicate rows (if any)\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Duplicate rows:\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6517225, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns with nan values \n",
    "\n",
    "USASTATE\n",
    "\n",
    "DEPE\n",
    "\n",
    "MEXSTATE\n",
    "\n",
    "CANPROV\n",
    "\n",
    "DF\n",
    "\n",
    "USASTATE            915116\n",
    "\n",
    "DEPE               4101624\n",
    "\n",
    "MEXSTATE           4677264\n",
    "\n",
    "CANPROV            3119497 \n",
    "\n",
    "Unique values in column CONTCODE:\n",
    "\n",
    "['Containerized' 'Non-Containerized' '1' 0 1]\n",
    "\n",
    "i have to check the unique columns in CONTCODE column and either remove anything \n",
    "\n",
    "other than 'Containerized' 'Non-Containerized' or rename it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTCODE column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with specified unique values in CONTCODE: 6517225\n"
     ]
    }
   ],
   "source": [
    "# Define the unique values to filter\n",
    "unique_values = ['Containerized', 'Non-Containerized', '1', 0, 1]\n",
    "\n",
    "# Filter the DataFrame for rows with the specified unique values in the CONTCODE column\n",
    "filtered_df = df[df['CONTCODE'].isin(unique_values)]\n",
    "\n",
    "# Count the number of rows in the filtered DataFrame\n",
    "num_rows = len(filtered_df)\n",
    "\n",
    "# Display the number of rows\n",
    "print(f\"Number of rows with specified unique values in CONTCODE: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each unique value in the CONTCODE column:\n",
      "CONTCODE\n",
      "Non-Containerized    3118231\n",
      "Containerized        2385964\n",
      "0                     504833\n",
      "1                     448877\n",
      "1                      59320\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each unique value in the CONTCODE column\n",
    "contcode_counts = df['CONTCODE'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of each unique value in the CONTCODE column:\")\n",
    "print(contcode_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated counts of each unique value in the CONTCODE column:\n",
      "CONTCODE\n",
      "Non-Containerized    3623064\n",
      "Containerized        2894161\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace 0, '1', and 1 with their respective types in the CONTCODE column\n",
    "df['CONTCODE'] = df['CONTCODE'].replace(0, 'Non-Containerized')\n",
    "df['CONTCODE'] = df['CONTCODE'].replace('1', 'Containerized')\n",
    "df['CONTCODE'] = df['CONTCODE'].replace(1, 'Containerized')\n",
    "\n",
    "# Drop rows with the value 1 in the CONTCODE column\n",
    "# df = df[df['CONTCODE'] != '1']\n",
    "# df = df[df['CONTCODE'] != 1]\n",
    "\n",
    "# Verify the changes by counting the number of each unique value in the CONTCODE column again\n",
    "contcode_counts_updated = df['CONTCODE'].value_counts()\n",
    "\n",
    "# Display the updated counts\n",
    "print(\"Updated counts of each unique value in the CONTCODE column:\")\n",
    "print(contcode_counts_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chk/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the TRDTYPE column:\n",
      "['Export' 'Import']\n",
      "\n",
      "\n",
      "Unique values in the USASTATE column:\n",
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'DU' 'FL' 'GA' 'HI' 'IA'\n",
      " 'ID' 'IL' 'IN' 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT'\n",
      " 'NC' 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC'\n",
      " 'SD' 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI' 'WV' 'WY' nan]\n",
      "\n",
      "\n",
      "Unique values in the DEPE column:\n",
      "['0115' '0901' '20XX' '2303' '2304' '2305' '2408' '2506' '3001' '3004'\n",
      " '3009' '3023' '30XX' '3101' '3103' '3104' '3106' '3126' '31XX' '3310'\n",
      " '3613' '3801' '3802' '4101' '4102' '41XX' '70XX' '0106' '01XX' '0701'\n",
      " '0708' '0712' '07XX' '09XX' '10XX' '17XX' '18XX' '19XX' '2006' '2301'\n",
      " '2310' '2401' '2402' '2403' '2404' '2503' '2507' '2601' '2604' '2608'\n",
      " '27XX' '3019' '3302' '33XX' '3401' '3403' '3422' '34XX' '3501' '35XX'\n",
      " '3604' '3803' '38XX' '5201' '5203' '52XX' '0209' '02XX' '0704' '3301'\n",
      " '3424' '5301' '55XX' '0715' '11XX' '24XX' '2501' '2603' '2605' '2606'\n",
      " '26XX' '2720' '2801' '29XX' '3011' '3020' '3318' '4115' '53XX' '0101'\n",
      " '0102' '0110' '0212' '13XX' '2302' '2307' '2504' '2505' '25XX' '2602'\n",
      " '2704' '28XX' '3002' '3003' '3005' '3007' '3008' '3013' '3025' '32XX'\n",
      " '3304' '3308' '3316' '3322' '3405' '3408' '3805' '3809' '3819' '3901'\n",
      " '39XX' '4105' '4110' '49XX' '5501' '3307' '45XX' '0104' '0211' '04XX'\n",
      " '1012' '1704' '80XX' '51XX' '0118' '0127' '14XX' '16XX' '3410' '36XX'\n",
      " '3808' '0108' '3306' '0105' '1003' '3012' '3321' '3323' '3404' '3014'\n",
      " '3423' '37XX' '3804' '0201' '0417' '2007' '3102' '0103' '0107' '0109'\n",
      " '0203' '0206' '3016' '3022' '3409' '3425' '3426' '3430' '3305' '3406'\n",
      " '3421' '3814' '1902' '3010' '3309' '3317' '0714' '15XX' '21XX' '54XX'\n",
      " '3407' '3413' '3414' '3415' '3416' '3417' '3419' '3420' '0207' '0904'\n",
      " '2406' '4104' '0112' '2383' '3701' '4103' '0121' '05XX' '2309' '23XX'\n",
      " '3303' '59XX' '3017' '3815' '3026' '3029' '3111' '1603' '3411' '3807'\n",
      " '3015' '4504' '1303' '3806' '0906' '3816' '0131' '0903' '1502' '3006' nan\n",
      " '2609' '3325' '0706' '3105' '3115' '60XX' '3427' '3324' '3384' '3842'\n",
      " '3018' '3818' '3882' '0905' '3433' '0182' '2481' '3082' '2407' '2502'\n",
      " '3843' '3434' '0111' '3881' '3385' '0152']\n",
      "\n",
      "\n",
      "Unique values in the DISAGMOT column:\n",
      "['Truck' 'Vessel' 'Air' 'Rail' 'Other' 'Pipeline'\n",
      " 'Mail (U.S. Postal Service)' 'Foreign Trade Zones (FTZs)']\n",
      "\n",
      "\n",
      "Unique values in the MEXSTATE column:\n",
      "[nan 'XX' 'CO' 'NL' 'CH' 'CM' 'GT' 'JA' 'MX' 'OT' 'QT' 'SL' 'BC' 'BS' 'DF'\n",
      " 'TM' 'ZA' 'DG' 'HG' 'SO' 'AG' 'MI' 'MO' 'PU' 'TL' 'VE' 'SI' 'YU' 'TB'\n",
      " 'CS' 'CL' 'OA' 'QR' 'GR']\n",
      "\n",
      "\n",
      "Unique values in the CANPROV column:\n",
      "['XB' 'XO' nan 'XA' 'XC' 'XM' 'XQ' 'XY' 'XW' 'XS' 'XN' 'XP' 'OT' 'XT' 'XV']\n",
      "\n",
      "\n",
      "Unique values in the COUNTRY column:\n",
      "['Canada' 'Mexico']\n",
      "\n",
      "\n",
      "Unique values in the VALUE column:\n",
      "[   4660   14360 4293733 ... 5148154 1168062 4384342]\n",
      "\n",
      "\n",
      "Unique values in the SHIPWT column:\n",
      "[       0 24971000      443 ...   663103  1823041  9137618]\n",
      "\n",
      "\n",
      "Unique values in the FREIGHT_CHARGES column:\n",
      "[     67     282       0 ... 1634298  127050  391893]\n",
      "\n",
      "\n",
      "Unique values in the DF column:\n",
      "['foreign pr. merch' 'domestic pr. merch' 'nan']\n",
      "\n",
      "\n",
      "Unique values in the CONTCODE column:\n",
      "['Containerized' 'Non-Containerized']\n",
      "\n",
      "\n",
      "Unique values in the MONTH column:\n",
      "['April' 'August' 'February' 'January' 'July' 'June' 'March' 'May'\n",
      " 'September' 'December' 'November' 'October']\n",
      "\n",
      "\n",
      "Unique values in the YEAR column:\n",
      "['2020' '2021' '2022' '2023' '2024']\n",
      "\n",
      "\n",
      "Unique values in the COMMODITY2 column:\n",
      "[ 0  2  3  4 10 13 19 23 26 27 29 39 44 48 62 63 72 73 74 76 83 84 85 86\n",
      " 87 88 90 94 95 98  1  5 11 12 15 16 17 18 20 21 25 28 30 31 32 33 34 35\n",
      " 38 40 47 49 54 55 56 57 58 59 60 61 64 65 67 68 69 70 75 78 81 82 89 93\n",
      " 96  7  8 22 36 42 51 71 79  6  9 24 41 52 53 80 91 92 97 14 37 43 45 46\n",
      " 66 50 99]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for each column in the DataFrame\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in the {column} column:\")\n",
    "    print(unique_values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USASTATE column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the USASTATE column:\n",
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'DU' 'FL' 'GA' 'HI' 'IA'\n",
      " 'ID' 'IL' 'IN' 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT'\n",
      " 'NC' 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC'\n",
      " 'SD' 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI' 'WV' 'WY' nan]\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the USASTATE column\n",
    "unique_usastate_values = df['USASTATE'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(\"Unique values in the USASTATE column:\")\n",
    "print(unique_usastate_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each unique value in the USASTATE column:\n",
      "USASTATE\n",
      "TX    351772\n",
      "CA    297422\n",
      "IL    239923\n",
      "OH    192662\n",
      "FL    188193\n",
      "PA    186369\n",
      "NY    185939\n",
      "MI    176640\n",
      "GA    171071\n",
      "NJ    167391\n",
      "WI    161793\n",
      "NC    159463\n",
      "IN    148913\n",
      "TN    144053\n",
      "MN    142770\n",
      "WA    133451\n",
      "MA    133384\n",
      "AZ    125711\n",
      "MO    124259\n",
      "KY    114667\n",
      "SC    114534\n",
      "VA    104937\n",
      "CO    102711\n",
      "CT     99657\n",
      "OR     96606\n",
      "IA     95297\n",
      "AL     93382\n",
      "KS     90782\n",
      "UT     89511\n",
      "MD     87618\n",
      "LA     78925\n",
      "NV     77195\n",
      "OK     76749\n",
      "MS     72381\n",
      "AR     68305\n",
      "NE     64453\n",
      "NH     64422\n",
      "ID     58856\n",
      "ME     58849\n",
      "RI     48462\n",
      "ND     48039\n",
      "DE     44542\n",
      "NM     44375\n",
      "MT     44148\n",
      "VT     42864\n",
      "SD     40785\n",
      "DU     37866\n",
      "WV     36769\n",
      "WY     26723\n",
      "AK     23931\n",
      "HI     13232\n",
      "DC      9357\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each unique value in the USASTATE column\n",
    "usastate_counts = df['USASTATE'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of each unique value in the USASTATE column:\")\n",
    "print(usastate_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NaN values in the USASTATE column: 915116\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in the USASTATE column\n",
    "usastate_nan_count = df['USASTATE'].isnull().sum()\n",
    "\n",
    "# Display the count of NaN values\n",
    "print(f\"Count of NaN values in the USASTATE column: {usastate_nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NaN values in the USASTATE column after dropping: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values in the USASTATE column\n",
    "df = df.dropna(subset=['USASTATE'])\n",
    "\n",
    "# Verify the changes by checking the count of NaN values in the USASTATE column again\n",
    "usastate_nan_count_after = df['USASTATE'].isnull().sum()\n",
    "\n",
    "# Display the count of NaN values after dropping to confirm the changes \n",
    "print(f\"Count of NaN values in the USASTATE column after dropping: {usastate_nan_count_after}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chk/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the TRDTYPE column:\n",
      "['Export' 'Import']\n",
      "\n",
      "\n",
      "Unique values in the USASTATE column:\n",
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'DU' 'FL' 'GA' 'HI' 'IA'\n",
      " 'ID' 'IL' 'IN' 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT'\n",
      " 'NC' 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC'\n",
      " 'SD' 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI' 'WV' 'WY']\n",
      "\n",
      "\n",
      "Unique values in the DEPE column:\n",
      "['0115' '0901' '20XX' '2303' '2304' '2305' '2408' '2506' '3001' '3004'\n",
      " '3009' '3023' '30XX' '3101' '3103' '3104' '3106' '3126' '31XX' '3310'\n",
      " '3613' '3801' '3802' '4101' '4102' '41XX' '70XX' '0106' '01XX' '0701'\n",
      " '0708' '0712' '07XX' '09XX' '10XX' '17XX' '18XX' '19XX' '2006' '2301'\n",
      " '2310' '2401' '2402' '2403' '2404' '2503' '2507' '2601' '2604' '2608'\n",
      " '27XX' '3019' '3302' '33XX' '3401' '3403' '3422' '34XX' '3501' '35XX'\n",
      " '3604' '3803' '38XX' '5201' '5203' '52XX' '0209' '02XX' '0704' '3301'\n",
      " '3424' '5301' '55XX' '0715' '11XX' '24XX' '2501' '2603' '2605' '2606'\n",
      " '26XX' '2720' '2801' '29XX' '3011' '3020' '3318' '4115' '53XX' '0101'\n",
      " '0102' '0110' '0212' '13XX' '2302' '2307' '2504' '2505' '25XX' '2602'\n",
      " '2704' '28XX' '3002' '3003' '3005' '3007' '3008' '3013' '3025' '32XX'\n",
      " '3304' '3308' '3316' '3322' '3405' '3408' '3805' '3809' '3819' '3901'\n",
      " '39XX' '4105' '4110' '49XX' '5501' '3307' '45XX' '0104' '0211' '04XX'\n",
      " '1012' '1704' '80XX' '51XX' '0118' '0127' '14XX' '16XX' '3410' '36XX'\n",
      " '3808' '0108' '3306' '0105' '1003' '3012' '3321' '3323' '3404' '3014'\n",
      " '3423' '37XX' '3804' '0201' '0417' '2007' '3102' '0103' '0107' '0109'\n",
      " '0203' '0206' '3016' '3022' '3409' '3425' '3426' '3430' '3305' '3406'\n",
      " '3421' '3814' '1902' '3010' '3309' '3317' '0714' '15XX' '21XX' '54XX'\n",
      " '3407' '3413' '3414' '3415' '3416' '3417' '3419' '3420' '0207' '0904'\n",
      " '2406' '4104' '0112' '2383' '3701' '4103' '0121' '05XX' '2309' '23XX'\n",
      " '3303' '59XX' '3017' '3815' '3026' '3029' '3111' '1603' '3411' '3807'\n",
      " '3015' '4504' '1303' '3806' '0906' '3816' '0131' '0903' '1502' '3006' nan\n",
      " '2609' '3325' '0706' '3105' '3115' '60XX' '3427' '3324' '3384' '3842'\n",
      " '3018' '3818' '3882' '0905' '3433' '0182' '2481' '3082' '2407' '2502'\n",
      " '3843' '3434' '0111' '3881' '3385' '0152']\n",
      "\n",
      "\n",
      "Unique values in the DISAGMOT column:\n",
      "['Truck' 'Vessel' 'Air' 'Rail' 'Other' 'Pipeline'\n",
      " 'Mail (U.S. Postal Service)' 'Foreign Trade Zones (FTZs)']\n",
      "\n",
      "\n",
      "Unique values in the MEXSTATE column:\n",
      "[nan 'XX' 'CO' 'NL' 'CH' 'CM' 'GT' 'JA' 'MX' 'OT' 'QT' 'SL' 'BC' 'BS' 'DF'\n",
      " 'TM' 'ZA' 'DG' 'HG' 'SO' 'AG' 'MI' 'MO' 'PU' 'TL' 'VE' 'SI' 'YU' 'TB'\n",
      " 'CS' 'CL' 'OA' 'QR' 'GR']\n",
      "\n",
      "\n",
      "Unique values in the CANPROV column:\n",
      "['XB' 'XO' nan 'XA' 'XC' 'XM' 'XQ' 'XY' 'XW' 'XS' 'XN' 'XP' 'OT' 'XT' 'XV']\n",
      "\n",
      "\n",
      "Unique values in the COUNTRY column:\n",
      "['Canada' 'Mexico']\n",
      "\n",
      "\n",
      "Unique values in the VALUE column:\n",
      "[   4660   14360 4293733 ... 1603515  308606 1629424]\n",
      "\n",
      "\n",
      "Unique values in the SHIPWT column:\n",
      "[       0 24971000      443 ...   197395   497144   108875]\n",
      "\n",
      "\n",
      "Unique values in the FREIGHT_CHARGES column:\n",
      "[    67    282      0 ... 106636 188593 129006]\n",
      "\n",
      "\n",
      "Unique values in the DF column:\n",
      "['foreign pr. merch' 'domestic pr. merch' 'nan']\n",
      "\n",
      "\n",
      "Unique values in the CONTCODE column:\n",
      "['Containerized' 'Non-Containerized']\n",
      "\n",
      "\n",
      "Unique values in the MONTH column:\n",
      "['April' 'August' 'February' 'January' 'July' 'June' 'March' 'May'\n",
      " 'September' 'December' 'November' 'October']\n",
      "\n",
      "\n",
      "Unique values in the YEAR column:\n",
      "['2020' '2021' '2022' '2023' '2024']\n",
      "\n",
      "\n",
      "Unique values in the COMMODITY2 column:\n",
      "[ 0  2  3  4 10 13 19 23 26 27 29 39 44 48 62 63 72 73 74 76 83 84 85 86\n",
      " 87 88 90 94 95 98  1  5 11 12 15 16 17 18 20 21 25 28 30 31 32 33 34 35\n",
      " 38 40 47 49 54 55 56 57 58 59 60 61 64 65 67 68 69 70 75 78 81 82 89 93\n",
      " 96  7  8 22 36 42 51 71 79  6  9 24 41 52 53 80 91 92 97 14 37 43 45 46\n",
      " 66 50 99]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for each column in the DataFrame\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in the {column} column:\")\n",
    "    print(unique_values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPE column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the DEPE column:\n",
      "['0115' '0901' '20XX' '2303' '2304' '2305' '2408' '2506' '3001' '3004'\n",
      " '3009' '3023' '30XX' '3101' '3103' '3104' '3106' '3126' '31XX' '3310'\n",
      " '3613' '3801' '3802' '4101' '4102' '41XX' '70XX' '0106' '01XX' '0701'\n",
      " '0708' '0712' '07XX' '09XX' '10XX' '17XX' '18XX' '19XX' '2006' '2301'\n",
      " '2310' '2401' '2402' '2403' '2404' '2503' '2507' '2601' '2604' '2608'\n",
      " '27XX' '3019' '3302' '33XX' '3401' '3403' '3422' '34XX' '3501' '35XX'\n",
      " '3604' '3803' '38XX' '5201' '5203' '52XX' '0209' '02XX' '0704' '3301'\n",
      " '3424' '5301' '55XX' '0715' '11XX' '24XX' '2501' '2603' '2605' '2606'\n",
      " '26XX' '2720' '2801' '29XX' '3011' '3020' '3318' '4115' '53XX' '0101'\n",
      " '0102' '0110' '0212' '13XX' '2302' '2307' '2504' '2505' '25XX' '2602'\n",
      " '2704' '28XX' '3002' '3003' '3005' '3007' '3008' '3013' '3025' '32XX'\n",
      " '3304' '3308' '3316' '3322' '3405' '3408' '3805' '3809' '3819' '3901'\n",
      " '39XX' '4105' '4110' '49XX' '5501' '3307' '45XX' '0104' '0211' '04XX'\n",
      " '1012' '1704' '80XX' '51XX' '0118' '0127' '14XX' '16XX' '3410' '36XX'\n",
      " '3808' '0108' '3306' '0105' '1003' '3012' '3321' '3323' '3404' '3014'\n",
      " '3423' '37XX' '3804' '0201' '0417' '2007' '3102' '0103' '0107' '0109'\n",
      " '0203' '0206' '3016' '3022' '3409' '3425' '3426' '3430' '3305' '3406'\n",
      " '3421' '3814' '1902' '3010' '3309' '3317' '0714' '15XX' '21XX' '54XX'\n",
      " '3407' '3413' '3414' '3415' '3416' '3417' '3419' '3420' '0207' '0904'\n",
      " '2406' '4104' '0112' '2383' '3701' '4103' '0121' '05XX' '2309' '23XX'\n",
      " '3303' '59XX' '3017' '3815' '3026' '3029' '3111' '1603' '3411' '3807'\n",
      " '3015' '4504' '1303' '3806' '0906' '3816' '0131' '0903' '1502' '3006' nan\n",
      " '2609' '3325' '0706' '3105' '3115' '60XX' '3427' '3324' '3384' '3842'\n",
      " '3018' '3818' '3882' '0905' '3433' '0182' '2481' '3082' '2407' '2502'\n",
      " '3843' '3434' '0111' '3881' '3385' '0152']\n",
      "Counts of each unique value in the DEPE column:\n",
      "DEPE\n",
      "2304    165205\n",
      "3802     61961\n",
      "20XX     61791\n",
      "0901     53226\n",
      "3401     51402\n",
      "         ...  \n",
      "2481         7\n",
      "3881         4\n",
      "0182         2\n",
      "0152         2\n",
      "3385         1\n",
      "Name: count, Length: 246, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the DEPE column\n",
    "unique_depe_values = df['DEPE'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(\"Unique values in the DEPE column:\")\n",
    "print(unique_depe_values)\n",
    "\n",
    "# Count the number of each unique value in the DEPE column\n",
    "depe_counts = df['DEPE'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of each unique value in the DEPE column:\")\n",
    "print(depe_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NaN values in the DEPE column: 4101624\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in the DEPE column\n",
    "depe_nan_count = df['DEPE'].isnull().sum()\n",
    "\n",
    "# Display the count of NaN values\n",
    "print(f\"Count of NaN values in the DEPE column: {depe_nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in the DataFrame\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.shape[0]}\")\n",
    "\n",
    "# Display the duplicate rows (if any)\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Duplicate rows:\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4101624)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DEPE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backup the DEPE column in df (DEPE_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\3033637106.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DEPE_backup'] = df['DEPE'].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing DEPE values: 4101624\n"
     ]
    }
   ],
   "source": [
    "# Backup the DEPE column\n",
    "df['DEPE_backup'] = df['DEPE'].copy()\n",
    "\n",
    "# Display the number of missing DEPE values\n",
    "print(f\"Number of rows with missing DEPE values: {df['DEPE'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4101624)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DEPE_backup'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5602109 entries, 0 to 6500079\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   TRDTYPE          object\n",
      " 1   USASTATE         object\n",
      " 2   DEPE             object\n",
      " 3   DISAGMOT         object\n",
      " 4   MEXSTATE         object\n",
      " 5   CANPROV          object\n",
      " 6   COUNTRY          object\n",
      " 7   VALUE            int64 \n",
      " 8   SHIPWT           int64 \n",
      " 9   FREIGHT_CHARGES  int64 \n",
      " 10  DF               object\n",
      " 11  CONTCODE         object\n",
      " 12  MONTH            object\n",
      " 13  YEAR             object\n",
      " 14  COMMODITY2       int64 \n",
      " 15  DEPE_backup      object\n",
      "dtypes: int64(4), object(12)\n",
      "memory usage: 726.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a mapping dictionary for district codes and port codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping dictionary for district codes and their corresponding port codes\n",
    "district_mapping = {\n",
    "    '01XX': ['0101', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0110', '0111', '0112', '0115', '0118', '0121', '0122', '0127', '0131', '0132', '0152', '0181', '0182'],\n",
    "    '02XX': ['0201', '0203', '0206', '0207', '0209', '0211', '0212'],\n",
    "    '04XX': ['0401', '0402', '0403', '0404', '0405', '0406', '0407', '0408', '0409', '0410', '0411', '0412', '0413', '0416', '0417'],\n",
    "    '05XX': ['0501', '0502', '0503'],\n",
    "    '07XX': ['0701', '0704', '0706', '0708', '0712', '0714', '0715'],\n",
    "    '09XX': ['0901', '0903', '0904', '0905', '0906', '0907', '0971', '0972', '0981'],\n",
    "    '10XX': ['1001', '1002', '1003', '1012'],\n",
    "    '11XX': ['1101', '1102', '1103', '1104', '1105', '1106', '1107', '1108', '1109', '1113', '1119', '1181', '1182', '1183', '1195'],\n",
    "    '13XX': ['1301', '1302', '1303', '1304', '1305'],\n",
    "    '14XX': ['1401', '1402', '1404', '1408', '1409', '1410', '1412'],\n",
    "    '15XX': ['1501', '1502', '1503', '1506', '1511', '1512'],\n",
    "    '16XX': ['1601', '1602', '1603', '1604', '1681'],\n",
    "    '17XX': ['1701', '1703', '1704'],\n",
    "    '18XX': ['1801', '1803', '1805', '1807', '1808', '1809', '1814', '1816', '1818', '1819', '1821', '1822', '1883', '1884', '1885', '1886', '1887'],\n",
    "    '19XX': ['1901', '1902', '1903', '1904', '1910'],\n",
    "    '20XX': ['2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2082', '2083', '2095'],\n",
    "    '21XX': ['2101', '2102', '2103', '2104'],\n",
    "    '23XX': ['2301', '2302', '2303', '2304', '2305', '2307', '2309', '2310', '2383', '2381'],\n",
    "    '24XX': ['2401', '2402', '2403', '2404', '2406', '2407', '2408', '2481'],\n",
    "    '25XX': ['2501', '2502', '2503', '2504', '2505', '2506', '2507'],\n",
    "    '26XX': ['2601', '2602', '2603', '2604', '2605', '2606', '2608', '2609'],\n",
    "    '27XX': ['2704', '2707', '2709', '2711', '2712', '2713', '2715', '2719', '2720', '2721', '2722', '2770', '2772', '2773', '2774', '2775', '2776', '2781', '2782', '2791', '2795'],\n",
    "    '28XX': ['2801', '2802', '2803', '2805', '2809', '2810', '2811', '2812', '2813', '2815', '2816', '2820', '2821', '2827', '2828', '2829', '2830', '2831', '2833', '2834', '2835', '2870', '2871', '2872', '2873', '2881', '2895'],\n",
    "    '29XX': ['2901', '2902', '2903', '2904', '2905', '2907', '2908', '2909', '2910'],\n",
    "    '30XX': ['3001', '3002', '3003', '3004', '3005', '3006', '3007', '3008', '3009', '3010', '3011', '3012', '3013', '3014', '3015', '3016', '3017', '3018', '3019', '3020', '3022', '3023', '3025', '3026', '3027', '3029', '3071', '3072', '3073', '3074', '3081', '3082', '3095'],\n",
    "    '31XX': ['3101', '3102', '3103', '3104', '3105', '3106', '3107', '3111', '3112', '3115', '3124', '3126', '3127', '3181', '3195', '3196'],\n",
    "    '32XX': ['3201', '3202', '3203', '3204', '3205', '3206', '3295'],\n",
    "    '33XX': ['3301', '3302', '3303', '3304', '3305', '3306', '3307', '3308', '3309', '3310', '3312', '3316', '3317', '3318', '3319', '3321', '3322', '3323', '3324', '3325', '3382', '3384', '3385'],\n",
    "    '34XX': ['3401', '3403', '3404', '3405', '3406', '3407', '3408', '3409', '3410', '3411', '3413', '3414', '3415', '3416', '3417', '3419', '3420', '3421', '3422', '3423', '3424', '3425', '3426', '3427', '3429', '3430', '3433', '3434', '3481'],\n",
    "    '35XX': ['3501', '3502', '3510', '3511', '3512', '3513', '3581'],\n",
    "    '36XX': ['3604', '3613', '3614'],\n",
    "    '37XX': ['3701', '3702', '3703', '3706', '3707', '3708'],\n",
    "    '38XX': ['3801', '3802', '3803', '3804', '3805', '3806', '3807', '3808', '3809', '3814', '3815', '3816', '3818', '3819', '3820', '3842', '3843', '3844', '3881', '3882'],\n",
    "    '39XX': ['3901', '3902', '3905', '3908', '3909', '3981', '3983', '3984', '3985', '3991'],\n",
    "    '41XX': ['4101', '4102', '4103', '4104', '4105', '4106', '4110', '4112', '4115', '4116', '4117', '4121', '4122', '4181', '4183', '4184', '4185', '4192', '4194', '4195', '4196', '4198'],\n",
    "    '45XX': ['4501', '4502', '4503', '4504', '4505', '4506'],\n",
    "    '46XX': ['4601', '4602', '4670', '4671', '4681'],\n",
    "    '47XX': ['4701', '4770', '4771', '4772', '4773', '4774', '4775', '4776', '4777', '4778'],\n",
    "    '49XX': ['4901', '4904', '4906', '4907', '4908', '4909', '4911', '4912', '4913'],\n",
    "    '51XX': ['5101', '5102', '5103', '5104', '5105'],\n",
    "    '52XX': ['5201', '5202', '5203', '5204', '5205', '5206', '5210', '5270', '5271', '5272', '5273', '5295', '5297', '5298'],\n",
    "    '53XX': ['5301', '5306', '5309', '5310', '5311', '5312', '5313', '5381'],\n",
    "    '54XX': ['5401', '5402'],\n",
    "    '55XX': ['5501', '5502', '5503', '5504', '5505', '5506', '5507', '5582', '5583', '5584'],\n",
    "    '60XX': ['60XX'],\n",
    "    '70XX': ['70XX'],\n",
    "    '80XX': ['80XX']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a reverse mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reverse mapping dictionary\n",
    "port_to_district_mapping = {}\n",
    "for district, ports in district_mapping.items():\n",
    "    for port in ports:\n",
    "        port_to_district_mapping[port] = district"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the mapping to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\3367896789.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DISTRICT'] = df['DEPE'].astype(str).map(port_to_district_mapping).fillna(df['DEPE'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the DISTRICT column after applying mapping:\n",
      "['01XX' '09XX' '20XX' '23XX' '24XX' '25XX' '30XX' '31XX' '33XX' '36XX'\n",
      " '38XX' '41XX' '70XX' '07XX' '10XX' '17XX' '18XX' '19XX' '26XX' '27XX'\n",
      " '34XX' '35XX' '52XX' '02XX' '53XX' '55XX' '11XX' '28XX' '29XX' '13XX'\n",
      " '32XX' '39XX' '49XX' '45XX' '04XX' '80XX' '51XX' '14XX' '16XX' '37XX'\n",
      " '15XX' '21XX' '54XX' '05XX' '59XX' nan '60XX']\n",
      "Counts of each unique value in the DISTRICT column:\n",
      "DISTRICT\n",
      "23XX    269639\n",
      "38XX    141807\n",
      "34XX    118098\n",
      "30XX    113634\n",
      "07XX     96141\n",
      "24XX     76697\n",
      "20XX     70984\n",
      "41XX     70564\n",
      "33XX     70529\n",
      "09XX     63959\n",
      "25XX     56730\n",
      "01XX     48627\n",
      "26XX     44458\n",
      "36XX     37063\n",
      "70XX     31779\n",
      "02XX     29417\n",
      "35XX     20179\n",
      "10XX     17048\n",
      "52XX     12817\n",
      "39XX     11742\n",
      "55XX     11361\n",
      "27XX     11325\n",
      "31XX      8075\n",
      "53XX      7579\n",
      "18XX      7331\n",
      "17XX      6969\n",
      "28XX      5363\n",
      "11XX      5306\n",
      "04XX      4496\n",
      "15XX      3627\n",
      "29XX      3458\n",
      "16XX      3427\n",
      "13XX      2780\n",
      "19XX      2754\n",
      "45XX      2641\n",
      "32XX      2486\n",
      "49XX      2341\n",
      "54XX      2170\n",
      "14XX      1695\n",
      "37XX      1496\n",
      "80XX       702\n",
      "05XX       491\n",
      "21XX       380\n",
      "51XX       222\n",
      "60XX        83\n",
      "59XX        15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply the reverse mapping to the DEPE column to create a new DISTRICT column\n",
    "df['DISTRICT'] = df['DEPE'].astype(str).map(port_to_district_mapping).fillna(df['DEPE'])\n",
    "\n",
    "# Verify the changes by checking the unique values again\n",
    "print(\"Unique values in the DISTRICT column after applying mapping:\")\n",
    "print(df['DISTRICT'].unique())\n",
    "\n",
    "# Count the number of each unique value in the DISTRICT column\n",
    "district_counts = df['DISTRICT'].value_counts()\n",
    "\n",
    "# Display the counts for DISTRICT\n",
    "print(\"Counts of each unique value in the DISTRICT column:\")\n",
    "print(district_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextual filling for missing DEPE values using mode within each USASTATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3540\\554642490.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('USASTATE').apply(fill_depe_with_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing DEPE values after filling: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to fill missing DEPE values with the mode of DEPE within each USASTATE\n",
    "def fill_depe_with_mode(group):\n",
    "    mode_depe = group['DEPE'].mode()\n",
    "    if not mode_depe.empty:\n",
    "        group['DEPE'] = group['DEPE'].fillna(mode_depe[0])\n",
    "    return group\n",
    "\n",
    "# Apply the function to fill missing DEPE values within each USASTATE\n",
    "df = df.groupby('USASTATE').apply(fill_depe_with_mode)\n",
    "\n",
    "# Verify that missing DEPE values have been filled\n",
    "print(f\"Number of rows with missing DEPE values after filling: {df['DEPE'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each unique value in the DISTRICT column:\n",
      "DISTRICT\n",
      "23XX    269639\n",
      "38XX    141807\n",
      "34XX    118098\n",
      "30XX    113634\n",
      "07XX     96141\n",
      "24XX     76697\n",
      "20XX     70984\n",
      "41XX     70564\n",
      "33XX     70529\n",
      "09XX     63959\n",
      "25XX     56730\n",
      "01XX     48627\n",
      "26XX     44458\n",
      "36XX     37063\n",
      "70XX     31779\n",
      "02XX     29417\n",
      "35XX     20179\n",
      "10XX     17048\n",
      "52XX     12817\n",
      "39XX     11742\n",
      "55XX     11361\n",
      "27XX     11325\n",
      "31XX      8075\n",
      "53XX      7579\n",
      "18XX      7331\n",
      "17XX      6969\n",
      "28XX      5363\n",
      "11XX      5306\n",
      "04XX      4496\n",
      "15XX      3627\n",
      "29XX      3458\n",
      "16XX      3427\n",
      "13XX      2780\n",
      "19XX      2754\n",
      "45XX      2641\n",
      "32XX      2486\n",
      "49XX      2341\n",
      "54XX      2170\n",
      "14XX      1695\n",
      "37XX      1496\n",
      "80XX       702\n",
      "05XX       491\n",
      "21XX       380\n",
      "51XX       222\n",
      "60XX        83\n",
      "59XX        15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each unique value in the DISTRICT column\n",
    "district_counts = df['DISTRICT'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of each unique value in the DISTRICT column:\")\n",
    "print(district_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the DISTRICT column after applying mapping:\n",
      "['01XX' '09XX' '20XX' '23XX' '24XX' '25XX' '30XX' '31XX' '33XX' '36XX'\n",
      " '38XX' '41XX' '70XX' '07XX' '26XX' '29XX' '32XX' '34XX' '39XX' nan '02XX'\n",
      " '17XX' '19XX' '52XX' '27XX' '28XX' '10XX' '60XX' '55XX' '35XX' '18XX'\n",
      " '13XX' '45XX' '11XX' '15XX' '53XX' '04XX' '54XX' '16XX' '80XX' '37XX'\n",
      " '14XX' '05XX' '49XX' '21XX' '51XX' '59XX']\n"
     ]
    }
   ],
   "source": [
    "# Verify the changes by checking the unique values again\n",
    "print(\"Unique values in the DISTRICT column after applying mapping:\")\n",
    "print(df['DISTRICT'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NaN values in the DISTRICT column: 4101624\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in the DISTRICT column\n",
    "district_nan_count = df['DISTRICT'].isnull().sum()\n",
    "\n",
    "# Display the count of NaN values\n",
    "print(f\"Count of NaN values in the DISTRICT column: {district_nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextual filling for missing DEPE values using mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing DEPE values: 4101624\n",
      "Number of rows with missing DEPE values after filling: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_29248\\1298587967.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DEPE'] = df_filled['DEPE']\n"
     ]
    }
   ],
   "source": [
    "# Display the number of missing DEPE values\n",
    "print(f\"Number of rows with missing DEPE values: {df['DEPE'].isnull().sum()}\")\n",
    "\n",
    "# Function to fill missing DEPE values with the mode of DEPE within each USASTATE\n",
    "def fill_depe_with_mode(group):\n",
    "    mode_depe = group['DEPE'].mode()\n",
    "    if not mode_depe.empty:\n",
    "        group['DEPE'] = group['DEPE'].fillna(mode_depe[0])\n",
    "    return group\n",
    "\n",
    "# Process each group separately and concatenate the results\n",
    "filled_df_list = []\n",
    "for name, group in df.groupby('USASTATE'):\n",
    "    filled_group = fill_depe_with_mode(group)\n",
    "    filled_df_list.append(filled_group)\n",
    "\n",
    "# Concatenate the filled groups\n",
    "df_filled = pd.concat(filled_df_list)\n",
    "\n",
    "# Update the original DataFrame with the filled values\n",
    "df['DEPE'] = df_filled['DEPE']\n",
    "\n",
    "# Verify that missing DEPE values have been filled\n",
    "print(f\"Number of rows with missing DEPE values after filling: {df['DEPE'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of each unique value in the DEPE column:\n",
      "DEPE\n",
      "2304    4115581\n",
      "3401      82944\n",
      "20XX      76603\n",
      "3310      75995\n",
      "3802      61961\n",
      "         ...   \n",
      "2481          7\n",
      "3881          4\n",
      "0182          2\n",
      "0152          2\n",
      "3385          1\n",
      "Name: count, Length: 246, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each unique value in the DEPE column\n",
    "depe_counts = df['DEPE'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts of each unique value in the DEPE column:\")\n",
    "print(depe_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NaN values in the DEPE column: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in the DEPE column\n",
    "depe_nan_count = df['DEPE'].isnull().sum()\n",
    "\n",
    "# Display the count of NaN values\n",
    "print(f\"Count of NaN values in the DEPE column: {depe_nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transBF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
